{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZzYJ+BW8qpVPpwWTqqfqS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitish-01/vision/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0n-JWghlv76"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import gc;\n",
        "gc.collect()\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So7DM2cGl_Y1"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')\n",
        "datapath = \"content/drive/My Drive/Colab Notebooks/data/cse7512-00-dl-tp-pt1/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9V9rtzAmCUf"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Colab Notebooks/data/cse7512-00-dl-tp-pt1.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPbCgamomFoV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "#def Model():\n",
        " #   r\"\"\"Return your custom model\n",
        "#    \"\"\"\n",
        " #   return resnet110()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCDy_gKBmIzn"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "def lr_poly(base_lr, i, max_i, power=0.95):\n",
        "    return base_lr * ((1-i/max_i) ** power)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # _, pred = output.topk(maxk, 1, True, True)\n",
        "        # pred = pred.t()\n",
        "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdizCXWamLxS"
      },
      "source": [
        "SAVEPATH = '/content/drive/My Drive/Colab Notebooks/data/'\n",
        "WEIGHTDECAY = 5e-4\n",
        "MOMENTUM = 0.9\n",
        "BATCHSIZE = 64\n",
        "LR = 0.1\n",
        "EPOCHS = 200\n",
        "PRINTFREQ = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFLtOGp6mOjb"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def get_test(batch_size, num_workers=1):\n",
        "    ''' Returns testing data loaders.\n",
        "    batch_size (int): Batch size.\n",
        "    num_workers (int): How many threads to use to load data. For deterministic behavior, set seed or set to 1.\n",
        "    '''\n",
        "    data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    test_datasets = datasets.stl10.STL10(root=\"data\", split=\"test\", transform=data_transform, download=True)\n",
        "    test_loaders = DataLoader(test_datasets, batch_size=batch_size, num_workers=1)\n",
        "\n",
        "    return test_loaders\n",
        "\n",
        "def test(model, test_loaders):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, batch_data in enumerate(test_loaders):\n",
        "        if torch.cuda.is_available():\n",
        "           image = batch_data[0].cuda() # torch.Size([batch, 3, 96, 96])\n",
        "           label = batch_data[1].cuda() # torch.Size([batch])\n",
        "\n",
        "        output = model(image) # torch.Size([batch, num_classes])\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        correct += int(torch.sum(preds == label)) # Add number of correct predictions to running total\n",
        "        total += int(label.size(0)) # Add batch size to total\n",
        "\n",
        "    print(\"Accuracy: {}\".format(correct / total))\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    model = resnet110()\n",
        "\n",
        "    ##### optimizer / learning rate scheduler / criterion #####\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR,\n",
        "                                momentum=MOMENTUM, weight_decay=WEIGHTDECAY,\n",
        "                                nesterov=True)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100, 150],\n",
        "                                                     gamma=0.1)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    ###########################################################\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "    # Check number of parameters your model\n",
        "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Number of parameters: {pytorch_total_params}\")\n",
        "    if int(pytorch_total_params) > 2000000:\n",
        "        print('Your model has the number of parameters more than 2 millions..')\n",
        "        return\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(96, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        './train', transform=train_transform)\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=BATCHSIZE, shuffle=True,\n",
        "                              num_workers=4, pin_memory=True)\n",
        "\n",
        "    last_top1_acc = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "            epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "        # train for one epoch\n",
        "        start_time = time.time()\n",
        "        last_top1_acc = train(train_loader, epoch, model, optimizer, criterion)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print('==> {:.2f} seconds to train this epoch\\n'.format(\n",
        "            elapsed_time))\n",
        "\n",
        "        # learning rate scheduling\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save model each epoch\n",
        "        torch.save(model.state_dict(), SAVEPATH+'model_weight.pth')\n",
        "        model.load_state_dict(torch.load(SAVEPATH+'model_weight.pth'))\n",
        "        test_loaders = get_test(BATCHSIZE)\n",
        "        test(model, test_loaders)\n",
        "\n",
        "\n",
        "    print(f\"Last Top-1 Accuracy: {last_top1_acc}\")\n",
        "    print(f\"Number of parameters: {pytorch_total_params}\")\n",
        "    \n",
        "\n",
        "\n",
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, data_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        if torch.cuda.is_available():\n",
        "           input = input.cuda()\n",
        "           target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % PRINTFREQ == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('=> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "          .format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwBxJsyimRd5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}